<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Add a new dataset &mdash; multimodal-vae-comparison 1.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="MultimodalVAE class" href="../code/trainer.html" />
    <link rel="prev" title="Add a new model" href="addmodel.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> multimodal-vae-comparison
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="addmodel.html">Add a new model</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Add a new dataset</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#supported-data-formats-config">Supported data formats, config</a></li>
<li class="toctree-l2"><a class="reference internal" href="#adding-a-new-dataset-class">Adding a new dataset class</a></li>
<li class="toctree-l2"><a class="reference internal" href="#different-data-formats">Different data formats</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code/trainer.html">MultimodalVAE class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/mmvae_base.html">Multimodal VAE Base Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/mmvae_models.html">Multimodal VAE models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/encoders.html">Encoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/decoders.html">Decoders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/vae.html">VAE class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/objectives.html">Objectives</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/dataloader.html">DataLoader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/datasets.html">Dataset Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/infer.html">Inference module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/eval_gebid.html">Evaluate on GeBiD dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../code/config_cls.html">Config class</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">multimodal-vae-comparison</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Add a new dataset</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorials/adddataset.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="add-a-new-dataset">
<span id="adddataset"></span><h1>Add a new dataset<a class="headerlink" href="#add-a-new-dataset" title="Permalink to this heading"></a></h1>
<p>By default, we support the proposed GeBiD dataset as well as MNIST, SVHN or the Caltech-UCSD Birds (CUB) dataset. Here we describe how
you can train the models on your own data.</p>
<section id="supported-data-formats-config">
<h2>Supported data formats, config<a class="headerlink" href="#supported-data-formats-config" title="Permalink to this heading"></a></h2>
<p>In general, the preferred data formats (supported by default) are:</p>
<ul class="simple">
<li><p>pickle (<code class="docutils literal notranslate"><span class="pre">.pkl</span></code>)</p></li>
<li><p>the pytorch format (<code class="docutils literal notranslate"><span class="pre">.pth</span></code>)</p></li>
<li><p>a directory containing <code class="docutils literal notranslate"><span class="pre">.png</span></code> images</p></li>
</ul>
<p>To train with any of these, specify the path to your data in the <code class="docutils literal notranslate"><span class="pre">config.yml</span></code>:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="w"> </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span><span class="w"></span>
<span class="w"> </span><span class="nt">epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">600</span><span class="w"></span>
<span class="w"> </span><span class="nt">exp_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cub</span><span class="w"></span>
<span class="w"> </span><span class="nt">labels</span><span class="p">:</span><span class="w"></span>
<span class="w"> </span><span class="nt">loss</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bce</span><span class="w"></span>
<span class="w"> </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-3</span><span class="w"></span>
<span class="w"> </span><span class="nt">mixing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">moe</span><span class="w"></span>
<span class="w"> </span><span class="nt">n_latents</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span><span class="w"></span>
<span class="w"> </span><span class="nt">obj</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">elbo</span><span class="w"></span>
<span class="w"> </span><span class="nt">optimizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">adam</span><span class="w"></span>
<span class="w"> </span><span class="nt">pre_trained</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span><span class="w"></span>
<span class="w"> </span><span class="nt">seed</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span><span class="w"></span>
<span class="w"> </span><span class="nt">viz_freq</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">10</span><span class="w"></span>
<span class="w"> </span><span class="nt">test_split</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span><span class="w"></span>
<span class="w"> </span><span class="nt">modality_1</span><span class="p">:</span><span class="w"></span>
<span class="hll"><span class="w">   </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./data/cub/images</span><span class="w"></span>
</span><span class="hll"><span class="w">   </span><span class="nt">mod_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">image</span><span class="w"></span>
</span><span class="hll"><span class="w">   </span><span class="nt">decoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CNN</span><span class="w"></span>
</span><span class="hll"><span class="w">   </span><span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">CNN</span><span class="w"></span>
</span><span class="hll"><span class="w"> </span><span class="nt">modality_2</span><span class="p">:</span><span class="w"></span>
</span><span class="w">   </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./data/cub/cub_captions.pkl</span><span class="w"></span>
<span class="hll"><span class="w">   </span><span class="nt">mod_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">text</span><span class="w"></span>
</span><span class="hll"><span class="w">   </span><span class="nt">decoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TxtTransformer</span><span class="w"></span>
</span><span class="hll"><span class="w">   </span><span class="nt">encoder</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TxtTransformer</span><span class="w"></span>
</span></pre></div>
</div>
<p>This is an example of the config file for the CUB dataset (for download, see our
<a class="reference external" href="https://github.com/gabinsane/multimodal-vae-comparison#training-on-other-datasets">README</a>).</p>
<p>As you can see, we specified the path to an image folder (<code class="docutils literal notranslate"><span class="pre">./data/cub/images</span></code>) and to the pickled captions (<code class="docutils literal notranslate"><span class="pre">./data/cub/cub_captions.pkl</span></code>). Both
modalities are expected to be ordered so that they can be semantically matched into pairs (e.g. the first image should match with the first caption).</p>
</section>
<section id="adding-a-new-dataset-class">
<h2>Adding a new dataset class<a class="headerlink" href="#adding-a-new-dataset-class" title="Permalink to this heading"></a></h2>
<p>If you wish to train on your own data, you will need to make a custom dataset class in <code class="docutils literal notranslate"><span class="pre">datasets.py</span></code>. Any new dataset must inherit
from BaseDataset to have some common methods used by the DataModule.</p>
<p>Here we show how we added CUB in datasets.py:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="nt">class CUB(BaseDataset)</span><span class="p">:</span><span class="w"></span>
<span class="linenos"> 2</span><span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">def __init__(self, pth, mod_type)</span><span class="p p-Indicator">:</span><span class="w"></span>
<span class="linenos"> 3</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">super().__init__(pth, mod_type)</span><span class="w"></span>
<span class="linenos"> 4</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">self.mod_type = mod_type</span><span class="w"></span>
<span class="linenos"> 5</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">self.path = pth</span><span class="w"></span>
<span class="linenos"> 6</span>
<span class="linenos"> 7</span><span class="w">    </span><span class="nt">def _mod_specific_fns(self)</span><span class="p">:</span><span class="w"></span>
<span class="linenos"> 8</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">return {&quot;image&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">self._process_images, &quot;text&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">self._process_text}</span><span class="w"></span>
<span class="linenos"> 9</span>
<span class="linenos">10</span><span class="w">    </span><span class="nt">def _process_images(self)</span><span class="p">:</span><span class="w"></span>
<span class="linenos">11</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">data = [torch.from_numpy(np.asarray(x.reshape(3, 64,64)).astype(np.float)) for x in self.get_data_raw()]</span><span class="w"></span>
<span class="linenos">12</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">return torch.stack(data)</span><span class="w"></span>
<span class="linenos">13</span>
<span class="linenos">14</span><span class="w">    </span><span class="nt">def _process_text(self)</span><span class="p">:</span><span class="w"></span>
<span class="linenos">15</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">self.has_masks = True</span><span class="w"></span>
<span class="linenos">16</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">self.categorical = True</span><span class="w"></span>
<span class="linenos">17</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">data = [&quot; &quot;.join(x) for x in self.get_data_raw()]</span><span class="w"></span>
<span class="linenos">18</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">data = [one_hot_encode(len(f), f) for f in data]</span><span class="w"></span>
<span class="linenos">19</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">data = [torch.from_numpy(np.asarray(x)) for x in data]</span><span class="w"></span>
<span class="linenos">20</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">masks = lengths_to_mask(torch.tensor(np.asarray([x.shape[0] for x in data]))).unsqueeze(-1)</span><span class="w"></span>
<span class="linenos">21</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">data = torch.nn.utils.rnn.pad_sequence(data, batch_first=True, padding_value=0.0)</span><span class="w"></span>
<span class="linenos">22</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">data_masks = torch.cat((data, masks), dim=-1)</span><span class="w"></span>
<span class="linenos">23</span><span class="w">        </span><span class="l l-Scalar l-Scalar-Plain">return data_masks</span><span class="w"></span>
</pre></div>
</div>
<p>Eventhough the dataset is multimodal, a new instance of it will be created for each modality. Therefore,
the constructor gets two arguments: path to the modality (str) and modality_type (str). Modality type is any string
that you assign to the given modality to distinguish it from the others. For CUB we chose “image” for images and “text” for text, for MNIST_SVHN
we have “mnist” and “svhn”. You specify mod_type in the config.</p>
<p>Next thing you need are methods that prepare each modality for training (_process_text and _process_images). Data loading is handled automatically by BaseDataset, so you
only perform reshaping, converting to tensors etc., so that these functions return tensors of the same length on the output.
Note: In case of sequential data (like text here), we make boolean masks and concatenate them with the last dimension of the text data. This is then automatically handled by the collate function</p>
<p>The last thing we need to do is map the data processing functions to the modality types, i.e. define _mod_specific_fns():</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">def _mod_specific_fns(self)</span><span class="p">:</span><span class="w"></span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">return {&quot;image&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">self._process_images, &quot;text&quot;</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">self._process_text}</span><span class="w"></span>
</pre></div>
</div>
<p>Here we just assign the methods to the selected mod_types. Once this is done, the dataset class should be ready and you can launch training.</p>
</section>
<section id="different-data-formats">
<h2>Different data formats<a class="headerlink" href="#different-data-formats" title="Permalink to this heading"></a></h2>
<p>If you want to train on an unsupported data format, you can file an issue on our <a class="reference external" href="https://github.com/gabinsane/multimodal-vae-comparison">GitHub repository</a>.
Alternatively, you can try to incorporate it on your own. You will need to adjust two methods in the <code class="docutils literal notranslate"><span class="pre">utils.py</span></code>.</p>
<p>First, add your new data format in <code class="docutils literal notranslate"><span class="pre">get_path_type()</span></code> so that it is recognised from the path.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_path_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    See if the provided data path is supported.</span>

<span class="sd">    :param path: Path to the dataset</span>
<span class="sd">    :type path: str</span>
<span class="sd">    :return: recognised type of the data</span>
<span class="sd">    :rtype: str</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">),</span> <span class="s2">&quot;Path does not exist: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="k">return</span> <span class="s2">&quot;dir&quot;</span>
    <span class="k">if</span> <span class="n">path</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span> <span class="o">==</span> <span class="s2">&quot;.pth&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;torch&quot;</span>
    <span class="k">if</span> <span class="n">path</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span> <span class="o">==</span> <span class="s2">&quot;.pkl&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;pickle&quot;</span>
    <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Unrecognized dataset format. Supported types are: .pkl, .pth or directory with images&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Next, decide how you will load the data.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads the data from path</span>

<span class="sd">    :return: data prepared for training</span>
<span class="sd">    :rtype: torch.tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_path_type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pth</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;dir&quot;</span><span class="p">:</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">load_images</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pth</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_dim</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;torch&quot;</span><span class="p">:</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pth</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dtype</span> <span class="o">==</span> <span class="s2">&quot;pickle&quot;</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pth</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">handle</span><span class="p">:</span>
             <span class="n">d</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_for_encoder</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">d</span>
</pre></div>
</div>
<p>ByPlease note that by default, we have incorporated encoders and decoders for images (preferably in 32x32x3 or 64x64x3 resolution, resp. 28x28x1 pixels for MNIST),
text data (arbitrary strings which we encode on the character-level) and sequential data (e.g. actions suitable for a Transformer network). If you add a new data structure or image resolution,
you will also need to add new encoder and decoder networks - you can then specify these in the config file.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="addmodel.html" class="btn btn-neutral float-left" title="Add a new model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../code/trainer.html" class="btn btn-neutral float-right" title="MultimodalVAE class" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Gabriela Sejnova.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>